{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4901,"status":"ok","timestamp":1647452779748,"user":{"displayName":"Daniel Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12604139581066463556"},"user_tz":360},"id":"uoOGThW_1kV9","outputId":"9a76ee0d-8c62-4f6c-cb4b-db8b0ccd7aa9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting icecream\n","  Using cached icecream-2.1.2-py2.py3-none-any.whl (8.3 kB)\n","Requirement already satisfied: colorama>=0.3.9 in c:\\users\\daniel\\appdata\\roaming\\python\\python310\\site-packages (from icecream) (0.4.4)\n","Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: asttokens>=2.0.1 in c:\\users\\daniel\\appdata\\roaming\\python\\python310\\site-packages (from icecream) (2.0.5)\n","Requirement already satisfied: executing>=0.3.1 in c:\\users\\daniel\\appdata\\roaming\\python\\python310\\site-packages (from icecream) (0.8.3)\n","Requirement already satisfied: pygments>=2.2.0 in c:\\users\\daniel\\appdata\\roaming\\python\\python310\\site-packages (from icecream) (2.11.2)\n","Requirement already satisfied: six in c:\\users\\daniel\\appdata\\roaming\\python\\python310\\site-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n","Installing collected packages: icecream\n","Successfully installed icecream-2.1.2\n","\n"]}],"source":["%pip install icecream"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1338,"status":"ok","timestamp":1647466602517,"user":{"displayName":"Daniel Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12604139581066463556"},"user_tz":360},"id":"n5W9l2jY9dTa","outputId":"ce6ece52-c848-42b6-93ea-d86d64abdf3f"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32md:\\School\\UofC_MDSA_2021\\DATA607\\project\\dz_tensorflow_plant_disease_test.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School/UofC_MDSA_2021/DATA607/project/dz_tensorflow_plant_disease_test.ipynb#ch0000001?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School/UofC_MDSA_2021/DATA607/project/dz_tensorflow_plant_disease_test.ipynb#ch0000001?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/School/UofC_MDSA_2021/DATA607/project/dz_tensorflow_plant_disease_test.ipynb#ch0000001?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School/UofC_MDSA_2021/DATA607/project/dz_tensorflow_plant_disease_test.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/UofC_MDSA_2021/DATA607/project/dz_tensorflow_plant_disease_test.ipynb#ch0000001?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39micecream\u001b[39;00m \u001b[39mimport\u001b[39;00m ic\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["# library imports\n","from datetime import datetime\n","import pandas as pd\n","import numpy as np\n","import pathlib\n","import os\n","import sys\n","import tensorflow as tf\n","import cv2\n","from icecream import ic\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"4y-bEMKk87SP"},"outputs":[],"source":["# add drive base file paths\n","# dataset is from https://www.kaggle.com/rashikrahmanpritom/plant-disease-recognition-dataset\n","base_folder_path = 'dataset/'\n","model_export_folder_path = 'models/'\n","tr_dir = base_folder_path + 'Train/Train/'\n","val_dir = base_folder_path + 'Validation/Validation/'\n","te_dir = base_folder_path + 'Test/Test/'"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"pY3wru_mF0Pe"},"outputs":[],"source":["EPOCHS = 10\n","IMG_WIDTH = int(168) # adjusted image width, original is 4000\n","IMG_HEIGHT = int(168) # adjusted image height, original is 2672\n","NUM_CATEGORIES = 3\n","TEST_SIZE = 0.4\n","categories_dict = {\n","    \"Healthy\": 0,\n","    \"Powdery\": 1,\n","    \"Rust\": 2\n","}\n","# for printing out predictions\n","inv_categories_dict = {v: k for k, v in categories_dict.items()} \n","\n","def load_data(data_dir, categories_dict):\n","    \"\"\"\n","    Load image data from directory `data_dir`.\n","    Assume `data_dir` has one directory named after each category, numbered\n","    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n","    number of image files.\n","    Return tuple `(images, labels)`. `images` should be a list of all\n","    of the images in the data directory, where each image is formatted as a\n","    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n","    be a list of integer labels, representing the categories for each of the\n","    corresponding `images`.\n","    \"\"\"\n","    images = list()\n","    labels = list()\n","\n","    # scan through directory and import all image files (resized before import)\n","    for itemA in os.scandir(data_dir):\n","        if itemA.is_dir():\n","            for itemB in os.scandir(itemA.path):\n","                if itemB.is_file():\n","                    # add image to list\n","                    img = cv2.imread(itemB.path)\n","                    resized_img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n","                    images.append(resized_img)\n","                    labels.append(categories_dict[itemA.name])\n","    return (np.array(images), np.array(labels))\n","\n","def get_model():\n","    \"\"\"\n","    Returns a compiled convolutional neural network model. Assume that the\n","    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n","    The output layer should have `NUM_CATEGORIES` units, one for each category.\n","    \"\"\"\n","    # model building references: https://pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n","    # model building references: https://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d\n","\n","\n","    model = tf.keras.models.Sequential([\n","        # convolutional layer, learn 16 filters using 7x7 kernal\n","        # max-pooling layer, using 2x2 pool size\n","        tf.keras.layers.Conv2D(32, (7, 7), activation=\"relu\", \n","                               input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n","        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.1),\n","\n","        # 2nd convolutional layer, learn 32 filters using 3x3 kernal\n","        # 2nd max-pooling layer, using 2x2 pool size\n","        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.2),\n","\n","        # 3rd convolutional layer, learn 64 filters using 3x3 kernal\n","        # 3rd max-pooling layer, using 2x2 pool size\n","        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.3),\n","\n","        # 4th convolutional layer, learn 128 filters using 3x3 kernal\n","        # 4th max-pooling layer, using 2x2 pool size\n","        tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.4),\n","\n","        # flatten\n","        tf.keras.layers.Flatten(),\n","\n","        # 512 unit hidden layer with 50% dropout\n","        tf.keras.layers.Dense(512, activation=\"relu\"),\n","        tf.keras.layers.Dropout(0.5),\n","\n","        # add output layer with output units for all of the signs\n","        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n","    ])\n","\n","    model.compile(\n","        optimizer=\"adam\",\n","        loss=\"categorical_crossentropy\",\n","        metrics=[\"accuracy\"]\n","    )\n","\n","    return model"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219171,"status":"ok","timestamp":1647469984269,"user":{"displayName":"Daniel Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12604139581066463556"},"user_tz":360},"id":"a7Jy0lIA9mhO","outputId":"ac286537-ba2a-4c5e-9c8b-02afe96300b4"},"outputs":[{"data":{"text/plain":["\"\\n# original data loading code\\nx_tr, y_tr = load_data(tr_dir, categories_dict)\\ny_tr = tf.keras.utils.to_categorical(y_tr, num_classes = 3, dtype = 'int')\\nic(x_tr.shape, y_tr.shape)\\n\\nx_val, y_val = load_data(val_dir, categories_dict)\\ny_val = tf.keras.utils.to_categorical(y_val, num_classes = 3, dtype = 'int')\\nic(x_val.shape, y_val.shape)\\n\\nx_te, y_te = load_data(te_dir, categories_dict)\\ny_te = tf.keras.utils.to_categorical(y_te, num_classes = 3, dtype = 'int')\\nic(x_te.shape, y_te.shape)\\n\""]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# file import\n","# load datasets\n","\n","\n","# editited code for spliting, \n","# did not like the original dataset's proportion where only 10% testing and 4% validation\n","# combine all available data together to form 1 dataset, \n","# and we will re-split data into training and testing sets using our defined proportions\n","images, labels = load_data(tr_dir, categories_dict)\n","images2, labels2 = load_data(val_dir, categories_dict)\n","images3, labels3 = load_data(te_dir, categories_dict)\n","images = np.append(images, np.append(images2, images3, axis = 0), axis = 0)\n","labels = np.append(labels, np.append(labels2, labels3, axis = 0), axis = 0)\n","\n","labels = tf.keras.utils.to_categorical(labels)\n","x_tr, x_te, y_tr, y_te = train_test_split(\n","    np.array(images), np.array(labels), test_size=TEST_SIZE\n",")\n","\n","# Additionally, evenlly split the training set again to training set and validation set\n","x_val, x_te, y_val, y_te = train_test_split(\n","    np.array(x_te), np.array(y_te), test_size=0.5\n",")\n","\n","'''\n","# original data loading code\n","x_tr, y_tr = load_data(tr_dir, categories_dict)\n","y_tr = tf.keras.utils.to_categorical(y_tr, num_classes = 3, dtype = 'int')\n","ic(x_tr.shape, y_tr.shape)\n","\n","x_val, y_val = load_data(val_dir, categories_dict)\n","y_val = tf.keras.utils.to_categorical(y_val, num_classes = 3, dtype = 'int')\n","ic(x_val.shape, y_val.shape)\n","\n","x_te, y_te = load_data(te_dir, categories_dict)\n","y_te = tf.keras.utils.to_categorical(y_te, num_classes = 3, dtype = 'int')\n","ic(x_te.shape, y_te.shape)\n","'''"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Mr30yp0-Dmsb","outputId":"8d0bb9dd-3bd2-4464-f830-fa396e1be5c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","29/29 [==============================] - 84s 3s/step - loss: 3.9767 - accuracy: 0.6366\n","Epoch 2/30\n","29/29 [==============================] - 89s 3s/step - loss: 1.8915 - accuracy: 0.8172\n","Epoch 3/30\n","29/29 [==============================] - 80s 3s/step - loss: 0.9845 - accuracy: 0.8945\n","Epoch 4/30\n","29/29 [==============================] - 75s 3s/step - loss: 1.1128 - accuracy: 0.8868\n","Epoch 5/30\n","28/29 [===========================>..] - ETA: 2s - loss: 0.4456 - accuracy: 0.9408"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17908/1612199184.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Fit model on training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Validate neural network performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Get a compiled neural network\n","model = get_model()\n","\n","# Fit model on training data\n","model.fit(x_tr, y_tr, epochs=EPOCHS)\n","\n","# Validate neural network performance\n","model.evaluate(x_val,  y_val, verbose=2)\n","\n","# Evaluate neural network performance\n","model.evaluate(x_te,  y_te, verbose=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2817,"status":"ok","timestamp":1647453914817,"user":{"displayName":"Daniel Zhou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12604139581066463556"},"user_tz":360},"id":"PqjF85vi9NNP","outputId":"22e806b3-6dcc-4c7a-f5e5-9758650ad69c"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/models/plant_disease_test_model/assets\n","Model saved to /content/drive/My Drive/Colab Notebooks/models/plant_disease_test_model.\n"]}],"source":["# Save model to file\n","model_name = 'plant_disease_test_model'\n","model.save(model_export_folder_path + model_name)\n","print(f\"Model saved to {model_export_folder_path + model_name}.\")"]}],"metadata":{"colab":{"name":"plant_disease_test.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.3"}},"nbformat":4,"nbformat_minor":0}
